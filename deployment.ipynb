{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "829e5abf-7cc8-4cda-979a-b14a453e522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deployment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deployment.py\n",
    "\n",
    "#Import of necessary libraries\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import cv2\n",
    "############################################################################\n",
    "\n",
    "#Functions use for preprocessing of images\n",
    "\n",
    "def hist_equalization_all(image):\n",
    "    #Converting image from BGR to RGB color space\n",
    "    RGB_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Split the RGB image into individual channels\n",
    "    r_channel, g_channel, b_channel = cv2.split(RGB_image)\n",
    "\n",
    "    #Apply histogram equalization to each channel\n",
    "    equalized_r_channel = cv2.equalizeHist(r_channel)\n",
    "    equalized_g_channel = cv2.equalizeHist(g_channel)\n",
    "    equalized_b_channel = cv2.equalizeHist(b_channel)\n",
    "\n",
    "    #Merge the equalized channels back into an RGB image\n",
    "    equalized_image = cv2.merge((equalized_r_channel, equalized_g_channel, equalized_b_channel))\n",
    "    \n",
    "    #Converting the RGB image back to BGR for the function, contrast_show()\n",
    "    equalized_image = cv2.cvtColor(equalized_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return equalized_image\n",
    "\n",
    "def increase_yellow_saturation_all(image):\n",
    "    #Converting the image from BGR to HSV color space\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #Define the lower and upper thresholds for yellow color in HSV\n",
    "    lower_yellow = np.array([20, 100, 100], dtype=np.uint8)\n",
    "    upper_yellow = np.array([40, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    #Creating a mask for yellow pixels\n",
    "    yellow_mask = cv2.inRange(image_hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    #Split the HSV image into individual channels\n",
    "    h, s, v = cv2.split(image_hsv)\n",
    "\n",
    "    #Increase the saturation of yellow pixels\n",
    "    s_yellow = s[yellow_mask > 0]\n",
    "    s_yellow = np.clip(s_yellow + 255, 0, 255)\n",
    "    s[yellow_mask > 0] = s_yellow\n",
    "\n",
    "    #Merging the modified channels back into the HSV image\n",
    "    image_hsv = cv2.merge((h, s, v))\n",
    "\n",
    "    #Convert the modified HSV image to BGR\n",
    "    modified_image = cv2.cvtColor(image_hsv, cv2.COLOR_HSV2BGR)\n",
    "   \n",
    "    return modified_image\n",
    "############################################################################\n",
    "\n",
    "#Setting title of the streamlit app\n",
    "st.title('Diseased Vegetable Image Classifier')\n",
    "\n",
    "#Loading of optimal model trained\n",
    "@st.cache_resource #to store the loaded model in cache for faster app run time \n",
    "def model_load():\n",
    "    model = tf.keras.models.load_model('MobileNetV2_model/model.19.h5')\n",
    "    return model\n",
    "\n",
    "model=model_load()\n",
    "\n",
    "#Extracting uploaded file\n",
    "file = st.file_uploader(\"For single images only. Note: Refrain from loading images with presence of water droplets for better results.\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "    \n",
    "if file is None:\n",
    "    st.write(f'<p style=\"font-size:26px;color:black;\">Upload an image above to start!</p>', unsafe_allow_html=True)\n",
    "else:\n",
    "    # Convert uploaded file to bytes in desired data type format\n",
    "    file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)\n",
    "\n",
    "    # Decode image using OpenCV\n",
    "    test_image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
    "    image_view = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Display of picture\n",
    "    st.image(image_view)\n",
    "\n",
    "    #Preprocessing methods\n",
    "    test_image = hist_equalization_all(test_image)\n",
    "    test_image = increase_yellow_saturation_all(test_image)\n",
    "\n",
    "    #Formatting images to fitting arrays and mobilenetv2 weights\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    test_image = preprocess_input(test_image)\n",
    "\n",
    "    #Gathering predictions\n",
    "    result = model.predict(test_image)\n",
    "    \n",
    "    for pred in result:\n",
    "        if pred[0] > 0.5:\n",
    "            text = 'Vegetable is classified as'\n",
    "            class01 = 'healthy'\n",
    "            st.write(f'<span style=\"font-size:26px;\">{text}</span> <span style=\"font-size:26px;color:lightgreen;\">{class01}</span>', \n",
    "                     unsafe_allow_html=True)\n",
    "        else:\n",
    "            text02 = 'Vegetable might be'\n",
    "            class02 = 'diseased'\n",
    "            text03 = 'Consider further checks.'\n",
    "            st.write(f'<span style=\"font-size:26px;\">{text02}</span> <span style=\"font-size:26px;color:red;\">{class02}</span>', unsafe_allow_html=True)\n",
    "            st.write(f'<span style=\"font-size:26px;\">{text03}</span>', unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122a64f-76fd-4e1a-b35c-e73b348995df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
